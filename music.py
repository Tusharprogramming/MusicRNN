# -*- coding: utf-8 -*-
"""Music

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hTh1TkxgJUOUY7lWLvvgFce3zEXrUDWU
"""

from music21 import *

import numpy as np
import tensorflow as tf
import os
import matplotlib.pyplot as plt

def read_midi(file):    
    notes=[]
    midi = converter.parse(file)
    parted = instrument.partitionByInstrument(midi)
    for part in parted.parts:   
        notes_to_parse = part.recurse()   
        for i in notes_to_parse:
            if isinstance(i, note.Note):
                    notes.append(str(i.pitch)) 
            elif isinstance(i, chord.Chord):
                    notes.append('.'.join(str(n) for n in i.normalOrder))
    return np.array(notes)

#path = '/content/drive/My Drive/maestro-v3.0.0/'

#files = []
#for i in os.listdir(path):
#  for j in os.listdir(path+i):
#    files.append(path+i+'/'+j)

path = '/content/drive/My Drive/testdata/'
files = []
for i in os.listdir(path):
  files.append(path+i)

song_array = np.array([read_midi(i) for i in files])

noteslist = [i for song in song_array for i in song]
uniques = list(set(noteslist))

print(len(uniques))

from collections import Counter
notefreq = dict(Counter(noteslist))
freqs = [count for _,count in notefreq.items()]
plt.figure(figsize=(5,5))
plt.hist(freqs)

keep_notes = [no for no,count in notefreq.items() if count >= 10]
print(len(keep_notes))

cutdown_songs = []
for song in song_array:
  newsong = []
  for note_ in song:
    if note_ in keep_notes:
      newsong.append(note_)
  cutdown_songs.append(newsong)

cutdown_songs = np.array(cutdown_songs)

no_of_timesteps = 32
x = []
y = []

for song in cutdown_songs:
    for i in range(0, len(song) - no_of_timesteps, 1):
        
        input_ = song[i:i + no_of_timesteps]
        output = song[i + no_of_timesteps]
        
        x.append(input_)
        y.append(output)
        
x=np.array(x)
y=np.array(y)

print(x.shape)
print(y.shape)

unique_x = list(set(x.ravel()))
x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))

x_seq=[]
for i in x:
    temp=[]
    for j in i:
        #assigning unique integer to every note
        temp.append(x_note_to_int[j])
    x_seq.append(temp)
    
x_seq = np.array(x_seq)
#x_seq = tf.cast(x_seq, 'float32')

unique_y = list(set(y))
y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) 
y_seq=np.array([y_note_to_int[i] for i in y])
#y_seq = tf.cast(y_seq, 'float32')

from sklearn.model_selection import train_test_split
x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0, train_size = 0.8)

a = x_tr.shape

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.LSTM(128,return_sequences=True))
model.add(tf.keras.layers.LSTM(128))
model.add(tf.keras.layers.Dense(400))
model.add(tf.keras.layers.Activation('softmax'))
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')

x_tr = x_tr.reshape(a[0], a[1],1)
x_tr = tf.cast(x_tr, 'float32')
y_tr = tf.cast(y_tr, 'float32')

model.fit(x_tr, y_tr, epochs= 15)

ind = np.random.randint(0,len(x_val)-1)
random_music = x_val[ind]

predictions=[]
for i in range(100):

    random_music = random_music.reshape(1,no_of_timesteps,1)

    prob  = model.predict(random_music)[0]
    y_pred= np.argmax(prob,axis=0)
    predictions.append(y_pred)

    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)
    random_music = random_music[1:]
    
print(predictions)



def convert_to_midi(prediction_output):
   
    offset = 0
    output_notes = []

    # create note and chord objects based on the values generated by the model
    for pattern in prediction_output:
        
        # pattern is a chord
        if ('.' in pattern) or pattern.isdigit():
            notes_in_chord = pattern.split('.')
            notes = []
            for current_note in notes_in_chord:
                
                cn=int(current_note)
                new_note = note.Note(cn)
                new_note.storedInstrument = instrument.Piano()
                notes.append(new_note)
                
            new_chord = chord.Chord(notes)
            new_chord.offset = offset
            output_notes.append(new_chord)
            
        # pattern is a note
        else:
            
            new_note = note.Note(pattern)
            new_note.offset = offset
            new_note.storedInstrument = instrument.Piano()
            output_notes.append(new_note)

        # increase offset each iteration so that notes do not stack
        offset += 1
    midi_stream = stream.Stream(output_notes)
    midi_stream.write('midi', fp='music8.mid')

x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) 
predicted_notes = [x_int_to_note[i] for i in predictions]
convert_to_midi(predicted_notes)

import shutil
shutil.copy("/content/music8.mid", "/content/drive/MyDrive/music8.mid")

from google.colab import files
files.download('music8.mid')

